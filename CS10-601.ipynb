{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMU 10-601 Machine Learning\n",
    "http://www.cs.cmu.edu/~ninamf/courses/601sp15/lectures.shtml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "We can represent any boolean value function over discrete values X_1 ... X_n with a decision tree.\n",
    "\n",
    "![alt text](./img/decision_tree.png \"Title\")\n",
    "\n",
    "### Problem Setting\n",
    "Set of possible instances X\n",
    "* Each instance x in X is a feature vector\n",
    "* x = {x_1,x_2...x_n}\n",
    "\n",
    "Unknown target function f: X->Y\n",
    "* Y is discrete valued\n",
    "\n",
    "Set of function hypothesis H={h|h:X->Y}\n",
    "* Each hypothesis h is adecision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "\\begin{equation*}\n",
    "H(X)=-\\sum_{i=1}^n P(X=i)\\log_2P(X=i)\n",
    "\\end{equation*}\n",
    "\n",
    "H(X) is the expected number of bits needed to encode a randomly drawn value of X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting & Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "Consider a hypotheosis h, and its\n",
    "* Error rate over training data: error_{train}(h)\n",
    "* True error rate over all data: error_{true}(h)\n",
    "we say h overfits the training data if\n",
    "\n",
    "error_{true}(h) > error_{train}(h)\n",
    "\n",
    "Amount of overfitting = error_{true}(h)-error_{train}(h)\n",
    "\n",
    "### Solution: Reduced-error pruning\n",
    "* Split data into training and validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Overview\n",
    "\n",
    "### Random Variables\n",
    "We have a sample space S, a random variable is a function defined over the sample space.\n",
    "\n",
    "### Principles for Estimating probabilities\n",
    "**Maximum likelihood**\n",
    "* choose parameters theta that maximize P(data|theta)\n",
    "\n",
    "**Maximum a posteriori prob**\n",
    "* choose parameter theta that maximize P(theta|data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
